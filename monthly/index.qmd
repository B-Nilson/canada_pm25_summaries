---
params:
  report: !expr source("../R/set_params.R"); set_params(type = "monthly")
title: "Canadian PM<sub>2.5</sub> Observations Monthly Summary for <mark class='bg-info'>`r params$report$display_name`</mark>"
subtitle: | 
  Non-validated, auto-QA/QCed data representing `r params$report$date_ranges$utc`<br>
  `r params$report$date_ranges$vancouver` in Vancouver |
  `r params$report$date_ranges$halifax` in Halifax
date: "`r params$report$date`"
citation: 
  id: monthly-report
  title: "Monthly Canada PM2.5 Summary"
  url: https://aqmap.ca/aqmap/reports/monthly
  publisher: "University of Northern British Columbia, Environment and Climate Change Canada"

format:
  html:
    pagetitle: "Monthly Canada PM2.5 Summary"
---

<meta name="viewport" content="width=device-width, initial-scale=1">

```{r setup}

source("R/report-functions.R")
source("R/report-constants.R")
report_dir <- report_dir |> file.path("monthly")
report_dir_esc <- report_dir_esc |> file.path("daily")

date_range <- report_dir |>
  get_report_start_end(type = "monthly", run_future = run_current_month)

old_report_dropdown <- report_dir |>
  handle_old_reports(report_pattern = "\\d\\.html$")

```

```{r load_data}

obs <- date_range |>
  load_report_data(
    meta_cols = meta_cols,
    cache_path = file.path(report_dir, "index_obs.rds"), # used when db not available
    provinces_n_territories = provinces_n_territories
  )
  
date_range <- range(obs$date)
hours_to_summarise <- date_range |> make_hourly_seq()
output_date_fmt <- date_range[2] |> format("%Y-%m")
plot_timestamp <- date_range[2] |>
  format("%Y-%m")
plot_captions <- date_range |>
  make_plot_captions(networks = names(monitor_groups))

summaries <- obs |>
  make_summaries(
    type = "monthly",
    fcst_zones = fcst_zones,
    meta_cols = meta_cols,
    report_dir = report_dir,
    figure_dir = figure_dir,
    plot_timestamp = plot_timestamp
  )

```

```{r getNetworkCoverage}

pop_rds = "../resources/spatial/canada_gridded_pop_census_2016.rds"
# If pop rds doesnt exist
if (!file.exists(pop_rds)) {
  neg_to_zero = \(x) ifelse(x < 0, 0, x)
  # Load gridded pop. data
  pop_shp = file.path(
    "../resources/spatial/griddedPopulationCanada10km_2016_shp",
    "griddedPopulationCanada10km_2016.shp"
  )
  pop_gridded = read_sf(pop_shp) |>
    # Choose desired columns (+geometry)
    dplyr::select(total = TOT_POP2A, urban = UR_POP2A, rural = RU_POP2A) |>
    # For some reason total not always urban + rural
    # This combines urban and rural as well as any extra pop in the total column
    dplyr::mutate(total = urban + rural + neg_to_zero(total - urban - rural)) |>
    # Drop 0 pop cells
    dplyr::filter(total > 0) |>
    st_transform(crs = "WGS84")

  # Flag by prov/terr
  pt = readRDS("../resources/spatial/aqmap_selection_zones.rds")[-14] |>
    dplyr::select(prov_terr = name)
  pop_gridded = st_join(pop_gridded, pt, left = TRUE, largest = TRUE)

  # Save RDS
  saveRDS(pop_gridded, pop_rds)
} else {
  # Otherwise, just use the rds
  pop_gridded = readRDS(pop_rds)
}

# Mark cell proximity to PA/FEM
locs = summaries$monthly |>
  dplyr::ungroup() |>
  dplyr::select(monitor, lat, lng) |>
  st_as_sf(coords = c("lng", "lat"), crs = "WGS84")
pop_centers = suppressWarnings(pop_gridded |> st_centroid())
pop_gridded_coverage = pop_gridded |>
  dplyr::mutate(
    cellID = 1:n(),
    has_nearby_fem = dplyr::filter(locs, monitor == "FEM") |>
      slice(st_nearest_feature(
        pop_centers,
        dplyr::filter(locs, monitor == "FEM")
      )) |>
      st_distance(x = pop_centers, by_element = TRUE),
    has_nearby_fem = as.numeric(has_nearby_fem) < 25000,
    has_nearby_pa = dplyr::filter(locs, monitor == "PA") |>
      slice(st_nearest_feature(
        pop_centers,
        dplyr::filter(locs, monitor == "PA")
      )) |>
      st_distance(x = pop_centers, by_element = TRUE),
    has_nearby_pa = as.numeric(has_nearby_pa) < 25000,
    has_nearby_monitor = has_nearby_fem | has_nearby_pa
  )

# Summarise PA / FEM / PA+FEM coverage by prov/terr
pop_coverage = pop_gridded_coverage |>
  # Flag province region
  flag_region()
pop_coverage = pop_coverage |>
  dplyr::bind_rows(dplyr::mutate(
    pop_coverage,
    region = "Canada",
    prov_terr = "Canada"
  )) |>
  dplyr::mutate(
    region = factor(region, c("West", "Central", "East", "North", "Canada")),
    prov_terr = factor(
      prov_terr,
      c(unlist(prov_pretty), "Canada"),
      c(names(prov_pretty), "CAN")
    )
  ) |>
  data.frame() |> # drop spatial column for time saving
  # Mark cells as having nearby FEM, PA, or both
  # dplyr::group_by(cellID) |>
  # dplyr::mutate(has_nearby_fem = any(has_nearby_monitor[network == "FEM Only"]),
  #        has_nearby_pa = any(has_nearby_monitor[network == "PA Only"])) |>
  # Get pop covered/uncovered in each prov/terr by each network
  dplyr::group_by(region, prov_terr, has_nearby_fem, has_nearby_pa) |>
  dplyr::summarise(
    dplyr::across(c(total, urban, rural), \(x) sum(x, na.rm = TRUE)),
    .groups = "drop"
  ) |>
  # Better network description
  dplyr::mutate(
    network = dplyr::case_when(
      has_nearby_fem & has_nearby_pa ~ "FEM and PA",
      has_nearby_fem ~ "FEM Only",
      has_nearby_pa ~ "PA Only",
      TRUE ~ "No Monitor"
    ) |>
      factor(c("FEM Only", "FEM and PA", "PA Only", "No Monitor"))
  ) |>
  dplyr::select(-has_nearby_pa, -has_nearby_fem) |>
  tidyr::pivot_longer(
    c(total, urban, rural),
    names_to = "pop_type",
    values_to = "pop"
  ) |>
  # dplyr::group_by(region) |>
  # tidyr::complete(prov_terr, network, pop_type) |>
  dplyr::mutate(pop = ifelse(is.na(pop), 0, pop)) |>
  # Get % coverages
  dplyr::group_by(region, prov_terr, pop_type) |>
  dplyr::mutate(
    total_pop = sum(pop, na.rm = TRUE),
    p_pop = round(pop / total_pop, 3)
  )

## FNIC coverage (First Nations and Inuit Communities == FNIC)
community_rds = "../resources/spatial/canada_communities.rds"
fnic_locs = readRDS(community_rds) |>
  dplyr::filter(type == "fnic") |>
  dplyr::select(region, prov_terr, name)

fnic_locs_coverage = fnic_locs |>
  dplyr::mutate(
    cellID = 1:n(),
    has_nearby_fem = dplyr::filter(locs, monitor == "FEM") |>
      slice(st_nearest_feature(
        fnic_locs,
        dplyr::filter(locs, monitor == "FEM")
      )) |>
      st_distance(x = fnic_locs, by_element = TRUE),
    has_nearby_fem = as.numeric(has_nearby_fem) < 25000,
    has_nearby_pa = dplyr::filter(locs, monitor == "PA") |>
      slice(st_nearest_feature(
        fnic_locs,
        dplyr::filter(locs, monitor == "PA")
      )) |>
      st_distance(x = fnic_locs, by_element = TRUE),
    has_nearby_pa = as.numeric(has_nearby_pa) < 25000,
    has_nearby_monitor = has_nearby_fem | has_nearby_pa
  )

data.table::fwrite(fnic_locs_coverage, "../../outputs/fnic_coverage.csv")

fnic_coverage = fnic_locs_coverage |>
  dplyr::bind_rows(dplyr::mutate(
    fnic_locs_coverage,
    region = "Canada",
    prov_terr = "Canada"
  )) |>
  dplyr::mutate(
    region = factor(region, c("West", "Central", "East", "North", "Canada")),
    prov_terr = factor(
      prov_terr,
      c(unlist(prov_pretty), "Canada"),
      c(names(prov_pretty), "CAN")
    )
  ) |>
  data.frame() |> # drop spatial column for time saving
  # Mark cells as having nearby FEM, PA, or both
  # dplyr::group_by(cellID) |>
  # dplyr::mutate(has_nearby_fem = any(has_nearby_monitor[network == "FEM Only"]),
  # has_nearby_pa = any(has_nearby_monitor[network == "PA Only"])) |>
  # Get fnic covered/uncovered in each prov/terr by each network
  dplyr::group_by(region, prov_terr, has_nearby_fem, has_nearby_pa) |>
  dplyr::summarise(pop = sum(rep(1, n(), na.rm = TRUE)), .groups = "drop") |>
  # Better network description
  dplyr::mutate(
    network = dplyr::case_when(
      has_nearby_fem & has_nearby_pa ~ "FEM and PA",
      has_nearby_fem ~ "FEM Only",
      has_nearby_pa ~ "PA Only",
      TRUE ~ "No Monitor"
    ) |>
      factor(c("FEM Only", "FEM and PA", "PA Only", "No Monitor"))
  ) |>
  dplyr::select(-has_nearby_pa, -has_nearby_fem) |>
  dplyr::mutate(pop_type = "fnic") |>
  # dplyr::group_by(region) |>
  # tidyr::complete(prov_terr, network, pop_type) |>
  dplyr::mutate(pop = ifelse(is.na(pop), 0, pop)) |>
  # Get % coverages
  dplyr::group_by(region, prov_terr, pop_type) |>
  dplyr::mutate(
    total_pop = sum(pop, na.rm = TRUE),
    p_pop = round(pop / total_pop, 3)
  )

coverage = dplyr::bind_rows(pop_coverage, fnic_coverage)

```

`r if(run_future_month) paste0("<center><h4>**WARNING - This report is incomplete. It only contains data up to ",max(obs$date) |> format("%B %d"),"**</h4></center>") |> HTML()`

|  

## Overview {.unlisted .unnumbered}

`r build_overview_card(type = "monthly", report_dropdown = old_report_dropdown)`

`r loading_div`

## Analysis of Past Month of PM<sub>2.5</sub> Observations

### How many observation sites at each risk level?

```{r prov_donuts}

# Define plot summary text (figure titles essentially)
plot_text_template <- "Distribution of monthly median concentrations at %s PM<sub>2.5</sub> monitoring sites within each province/territory. The number within each circle indicates the total number of monitors with data in that area. Percents indicate the amount of those monitors with a monthly median within that concentration range." |>
  sprintf(monitor_groups)
prov_donuts_text <- list(
  median = plot_text_template,
  max = plot_text_template |> stringr::str_replace_all(" mean ", " max ")
) |>
  lapply(\(x) as.list(x) |> setNames(monitor_groups))

# Make summary data for autmated text for this section
prov_donuts_text$p <- c(pa = "PA", fem = "FEM") |>
  lapply(\(network) {
    summaries$donuts$data$median |>
      dplyr::filter(monitor == network) |>
      dplyr::group_by(monitor, aqhi_p) |>
      dplyr::summarise(n = sum(n), .groups = "drop") |>
      dplyr::mutate(p = round(n / sum(n) * 100, 1))
  })

```

`r build_prov_donut_summary(prov_donuts_text, type = "monthly")`

`r tab_explainers$network_tabs`

#### FEM and PA

```{r include=TRUE, results = 'asis'}
summaries$donuts$paths$median_fem_and_pa |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(prov_donuts_text$mean$`FEM and PA`)
```

```{r include=TRUE, results = 'asis'}
summaries$donuts$paths$max_fem_and_pa |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(prov_donuts_text$max$`FEM and PA`)
```

#### FEM Only

```{r include=TRUE, results = 'asis'}
summaries$donuts$paths$median_fem_only |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(prov_donuts_text$mean$`FEM Only`)
```

```{r include=TRUE, results = 'asis'}
summaries$donuts$paths$max_fem_only |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(prov_donuts_text$max$`FEM Only`)
```

#### PA Only

```{r include=TRUE, results = 'asis'}
summaries$donuts$paths$median_pa_only |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(prov_donuts_text$mean$`PA Only`)
```

```{r include=TRUE, results = 'asis'}
summaries$donuts$paths$max_pa_only |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(prov_donuts_text$max$`PA Only`)
```

### Who had access to nearby observations? {.panel-tabset}

```{r coverage_charts}
fig_dims = list(h = 7, w = 9, u = 'in')

c_types = c("urban", "rural", "total", "fnic")
coverage_barcharts = lapply(c_types, \(p) {
  coverage |>
    dplyr::filter(pop_type == p) |>
    pop_coverage_barchart(p)
}) |>
  setNames(c_types)

plot_paths = paste0(
  report_dir,
  "plots/coverage_",
  c_types,
  "_",
  output_date_fmt,
  ".png"
) |>
  as.list() |>
  setNames(c_types)

for (ct in names(plot_paths)) {
  ggsave(
    coverage_barcharts[[ct]],
    filename = plot_paths[[ct]],
    dpi = 300,
    units = fig_dims$u,
    height = fig_dims$h,
    width = fig_dims$w
  )
}
plot_text = paste(
  "Estimated percentage of Canadian %c within 25 km of a",
  "regulatory (FEM) and/or low-cost PurpleAir (PA) PM<sub>2.5</sub> monitor",
  "during the month of",
  format(date_range[2], "%B, %Y."),
  "The patterned section shows overlapping coverage of the two networks (i.e. %c covered by both networks).",
  "Data for %c sourced from %s."
)

# Make coverage table
td = coverage |>
  dplyr::select(-total_pop) |>
  dplyr::mutate(p_pop = paste0(p_pop * 100, "%")) |>
  tidyr::pivot_wider(names_from = pop_type, values_from = c(pop, p_pop)) |>
  dplyr::arrange(region, prov_terr, network) |>
  dplyr::mutate(dplyr::across(
    c(pop_fnic, pop_rural, pop_urban, pop_total),
    \(p) format(ifelse(is.na(p), 0, p), big.mark = ",")
  )) |>
  dplyr::select(
    Region = region,
    `Prov./Terr.` = prov_terr,
    "Within 25km of" = network,
    pop_fnic,
    p_pop_fnic,
    pop_rural,
    p_pop_rural,
    pop_urban,
    p_pop_urban,
    pop_total,
    p_pop_total
  )
coverage_table = reactable(
  data = td,
  pagination = FALSE,
  columns = list(
    pop_fnic = reactable::colDef("Count"),
    p_pop_fnic = reactable::colDef("Percentage"),
    pop_total = reactable::colDef("Count"),
    p_pop_total = reactable::colDef("Percentage"),
    pop_rural = reactable::colDef("Count"),
    p_pop_rural = reactable::colDef("Percentage"),
    pop_urban = reactable::colDef("Count"),
    p_pop_urban = reactable::colDef("Percentage")
  ),
  columnGroups = list(
    reactable::colGroup(
      name = "FN & Inuit Communities",
      columns = c("pop_fnic", "p_pop_fnic")
    ),
    reactable::colGroup(
      name = "Total Pop. (2016)",
      columns = c("pop_total", "p_pop_total")
    ),
    reactable::colGroup(
      name = "Urban Pop. (2016)",
      columns = c("pop_urban", "p_pop_urban")
    ),
    reactable::colGroup(
      name = "Rural Pop. (2016)",
      columns = c("pop_rural", "p_pop_rural")
    )
  )
)
coverage_dl = td |>
  download_this(
    output_name = "network_coverage_" |>
      paste0(max(obs$date) |> format("%Y-%B")),
    output_extension = ".csv",
    sep = ",",
    dec = ".",
    button_label = "Download data as csv",
    button_type = "default",
    has_icon = TRUE,
    csv2 = FALSE,
    icon = "fa fa-save"
  )

```

`r build_coverage_summary(td)`

`r tab_explainers$scale_tabs`

#### Total Population

```{r include=TRUE, results = 'asis'}
plot_paths$total |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(
    plot_text |>
      stringr::str_replace_all("%c", "total population") |>
      stringr::str_replace_all(
        "%s",
        "the gridded 2016 census: https://open.canada.ca/data/en/dataset/c6c48391-fd2f-4d8a-93c8-eb74f58a859b"
      )
  )
```

#### First Nations and Inuit Communities

```{r include=TRUE, results = 'asis'}
plot_paths$fnic |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(
    plot_text |>
      stringr::str_replace_all("%c", "First Nation and Inuit communities") |>
      stringr::str_replace_all(
        "%s",
        "https://open.canada.ca/data/en/dataset/b6567c5c-8339-4055-99fa-63f92114d9e4 and https://open.canada.ca/data/en/dataset/2bcf34b5-4e9a-431b-9e43-1eace6c873bd"
      )
  )
```

#### Urban Population

```{r include=TRUE, results = 'asis'}
plot_paths$urban |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(
    plot_text |>
      stringr::str_replace_all("%c", "urban population") |>
      stringr::str_replace_all(
        "%s",
        "the gridded 2016 census: https://open.canada.ca/data/en/dataset/c6c48391-fd2f-4d8a-93c8-eb74f58a859b"
      )
  )
```

#### Rural Population

```{r include=TRUE, results = 'asis'}
plot_paths$rural |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(
    plot_text |>
      stringr::str_replace_all("%c", "rural population") |>
      stringr::str_replace_all(
        "%s",
        "the gridded 2016 census: https://open.canada.ca/data/en/dataset/c6c48391-fd2f-4d8a-93c8-eb74f58a859b"
      )
  )
```

#### Coverage Table

```{r include = TRUE, cache = FALSE}
coverage_dl
coverage_table
```

### Where and when were PM<sub>2.5</sub> concentrations high? {.panel-tabset}

```{r, maps}

# Daily Zone Summaries ----------------------------------------------------

legend_title = "Daily Mean<br>PM<sub>2.5</sub> (μg m<sup>-3</sup>)"

plot_text = "Interactive map summarizing the daily mean concentrations from both FEM and PA monitors by forecast zone for the month. You can use the control menu in the top right to step through the days in the month. If you hover over a forecast zone a summary popup will appear for that zone for the displayed day."
plot_title = paste0(
  "Animated Map of Daily Forecast Zone Mean PM<sub>2.5</sub> for ",
  format(date_range[2], "%B %Y")
)
plot_path = paste0(
  report_dir,
  "plots/fcstzone_mean_map_daily_",
  output_date_fmt,
  ".html"
)


# To add slider controls see jsfiddle.net/qs6dL200
map = make_anim_map(summaries$daily_by_zone, legend_title, height = 600)

mapview::mapshot(map, plot_path, libdir = "./libs", selfcontained = FALSE)

# Monthly Zone Summaries ----------------------------------------------------

plot2_text = "Interactive map summarizing the monthly mean concentrations from both FEM and PA monitors by forecast zone. On the left the mean values are presented, and max values are presented on the right. If you hover over a forecast zone a summary popup will appear for that zone."
plot2_title = paste0(
  "Map of Forecast Zone Mean [left] and Max [right] for ",
  format(date_range[2], "%B %Y")
)
plot2_path = paste0(
  report_dir,
  "plots/fcstzone_mean_map_",
  output_date_fmt,
  ".html"
)

legend_titles = list()
legend_titles$pm25 = legend_title |>
  stringr::str_replace("Daily", format(date_range[2], "%b."))
legend_titles$pm25_max = legend_titles$pm25 |>
  stringr::str_replace("Mean", "Max")

map = make_sync_map(
  summaries$monthly_by_zone,
  cols = c("pm25", "pm25_max"),
  legend_titles
)

htmltools::save_html(map, plot2_path, libdir = "./libs")

```

`r build_map_summary(summaries$aqhi_p_counts, type = "monthly", worst_day = summaries$worst_day)`

`r tab_explainers$scale_tabs`

#### Daily

```{r include=TRUE, results = 'asis'}
plot_path |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_text, iframe = TRUE, plot_title)
```

#### Monthly

```{r include=TRUE, results = 'asis'}
plot2_path |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot2_text, iframe = TRUE, plot2_title, iframe_height = 625)
```

### Where and when did PM<sub>2.5</sub> events occur? {.panel-tabset}

```{r grids_prov}

# Make data for prov/terr grid plots
grid_data <- list(median = median, maximum = max) |>
  lapply(\(FUN) obs |> make_grid_data(FUN = FUN, type = "monthly"))
grid_xlab <- "Day of %s" |> sprintf(format(date_range[2], "%B"))

# Make paths to plot files
plot_paths <- grid_data |>
  make_and_save_prov_terr_grids(
    report_dir = report_dir,
    figure_dir = figure_dir,
    monitor_groups = monitor_groups,
    plot_timestamp = plot_timestamp,
    xlab = grid_xlab,
    plot_captions = plot_captions
  )

# Define plot summary text (figure titles essentially)
plot_texts <- paste(
  "Median and maximum daily PM<sub>2.5</sub> concentrations",
  "for all %s monitoring sites in each province/territory.",
  "The median is useful for identifying large scale impacts across the province/territory,",
  "while the maximum can be used to identify impacts in at least one area of the province/territory."
) |>
  sprintf(names(monitor_groups)) |>
  setNames(monitor_groups) |>
  as.list()

```

`r tab_explainers$scale_tabs`

#### Province Level {.panel-tabset}

`r build_prov_grid_summary(grid_data, type = "monthly")`

`r tab_explainers$network_tabs`

##### FEM and PA

```{r grids_both, include=TRUE, results = 'asis'}
plot_paths[['FEM and PA']] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[['FEM and PA']])
```

##### FEM Only

```{r grids_fem, include=TRUE, results = 'asis'}
plot_paths[['FEM']] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[['FEM Only']])
```

##### PA Only

```{r grids_pa, include=TRUE, results = 'asis'}
plot_paths[['PA']] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[['PA Only']])
```

#### Region Level {.panel-tabset}

```{r grids_fcst, include= FALSE}

# Make data and save fcst_zone grid plots
fcst_grid_data <- obs |>
  dplyr::mutate(monitor = "FEM and PA") |>
  make_grid_data(FUN = median, type = "monthly", fcst_zones = fcst_zones)

plot_paths <- fcst_grid_data |>
  make_and_save_fcst_zone_grids(
    report_dir = report_dir,
    figure_dir = figure_dir,
    plot_timestamp = plot_timestamp,
    xlab = grid_xlab,
    plot_caption = plot_captions$`FEM and PA`,
    provinces_n_territories = provinces_n_territories
  )

# Define plot summary text (figure titles essentially)
plot_texts <- paste(
  "Daily median PM<sub>2.5</sub> concentrations for all monitors (FEM and PA) within each forecast zone for %s.",
  "A white cell indicates there was no data for that day from any monitor within that zone.",
  "Zones are grouped into those with and those without data and are sorted alphabetically."
) |>
  sprintf(provinces_n_territories) |>
  setNames(provinces_n_territories) |>
  as.list()

```

`r build_fcst_grid_summary(fcst_grid_data, type = "monthly")`

`r tab_explainers$prov_terr_tabs`

```{r include = TRUE, results="asis"}

for (pt_name in names(provinces_n_territories)) {
  pt_abbr <- provinces_n_territories[[pt_name]]
  cat("##### ", pt_abbr, "\n")
  cat(
    plot_paths[[pt_abbr]] |>
      stringr::str_replace(report_dir_esc, "./") |>
      plot_card(plot_texts[[pt_abbr]]),
    "\n"
  )
}

```

### Which sites had the highest concentrations? {.panel-tabset}

```{r site_boxplots}

boxplots <- summaries$overall |>
  make_and_save_site_boxplots(
    monitor_groups = monitor_groups,
    date_range = date_range,
    date_format = "%Y-%m-%d",
    avg_text = "Monthly",
    plot_timestamp = plot_timestamp,
    report_dir = report_dir,
    figure_dir = figure_dir,
    lib_dir = lib_dir
  )

plot_paths <- boxplots$paths

# Define text for below plots (figure title essentially)
plot_texts = paste0(
  "Each boxplot summarises the distribution of monthly monitoring site (",
  monitor_groups,
  ") mean PM<sub>2.5</sub> concentrations for that province/territory. Blue points for individual sites are displayed for any monitors higher than that regions 75th percentile. Hover over the blue points (if present) to see details about that specific site; hover over the boxplot (away from the points) to see the min/median/max and 25th/75th percentiles for that province. See the menu in the top right of the plot for more."
) |>
  as.list() |>
  setNames(monitor_groups)

```

`r build_boxplot_summary(boxplots$summary_values, type = "monthly")`  

`r tab_explainers$network_tabs`

#### FEM and PA

```{r include=TRUE, results = 'asis'}
plot_paths[["FEM and PA"]] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[["FEM and PA"]], iframe = TRUE)
```

#### FEM Only

```{r include=TRUE, results = 'asis'}
plot_paths[["FEM"]] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[["FEM Only"]], iframe = TRUE)
```

#### PA Only

```{r include=TRUE, results = 'asis'}
plot_paths[["PA"]] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[["PA Only"]], iframe = TRUE)
```

### Which communities [with data] had very high PM<sub>2.5</sub>? {.panel-tabset}

```{r community_boxplots}

# Get data for site mean boxplots
pd = summaries$overall |>
  dplyr::mutate(
    monitor2 = ifelse(
      monitor == "FEM",
      "FEM Only",
      ifelse(monitor == "PA", "PA Only", "FEM and PA")
    )
  ) |>
  dplyr::bind_rows(
    summaries$overall |>
      dplyr::mutate(monitor2 = "FEM and PA") |>
      dplyr::group_by(prov_terr, fcst_zone, nearest_community, monitor2) |>
      dplyr::summarise(
        n_hours_above_30 = max(n_hours_above_30, na.rm = TRUE),
        n_hours_above_60 = max(n_hours_above_60, na.rm = TRUE),
        n_hours_above_100 = max(n_hours_above_100, na.rm = TRUE),
        pm25_mean = mean(pm25_mean, na.rm = TRUE),
        pm25_max = max(pm25_max, na.rm = TRUE),
        n_sites = sum(n_sites, na.rm = TRUE)
      )
  ) |>
  dplyr::mutate(aqhi_p_mean = aqhi_p(pm25_mean)) |>
  dplyr::full_join(expand.grid(
    prov_terr = unlist(prov_order),
    monitor2 = monitor_groups,
    date_max = unique(summaries$overall$date_max)
  )) |>
  dplyr::mutate(date = date_max)
# Make paths to files for saving plots
plot_paths = paste0(
  report_dir,
  "plots/communities_veryHigh_hours_",
  monitor_groups_cleaned,
  '_',
  output_date_fmt,
  ".html"
) |>
  setNames(monitor_groups) |>
  as.list()
# MAke and save plots
.tmp = lapply(monitor_groups, \(m) {
  pd |>
    subset(monitor2 == m) |>
    make_community_boxplots(m) |>
    htmlwidgets::saveWidget(
      plot_paths[[m]],
      libdir = "./libs",
      selfcontained = FALSE
    )
}) |>
  setNames(monitor_groups)
# Define text for below plots (figure title essentially)
plot_texts = paste0(
  "Each boxplot summarises the distribution of 1-month community counts of hours with PM<sub>2.5</sub> concentrations above 100 {{< pm_units >}} for at least one monitoring site (",
  monitor_groups,
  ") in that community for each province/territory. Blue points for individual communities are displayed for any communities with counts higher than that regions 75th percentile. Hover over the blue points (if present) to see details about that specific community; hover over the boxplot (away from the points) to see the min/median/max and 25th/75th percentiles for that province/territory. See the menu in the top right for more."
) |>
  as.list() |>
  setNames(monitor_groups)

```

`r build_community_summary(summaries$community, type = "monthly")`

`r tab_explainers$network_tabs`

#### FEM and PA

```{r include=TRUE, results = 'asis'}
plot_paths[["FEM and PA"]] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[["FEM and PA"]], iframe = TRUE)
```

#### FEM Only

```{r include=TRUE, results = 'asis'}
plot_paths[["FEM Only"]] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[["FEM Only"]], iframe = TRUE)
```

#### PA Only

```{r include=TRUE, results = 'asis'}
plot_paths[["PA Only"]] |>
  stringr::str_replace(report_dir_esc, "./") |>
  plot_card(plot_texts[["PA Only"]], iframe = TRUE)
```

### What was the worst day this month? {.panel-tabset}

```{r worst_day_tables}
# Make download link and table for province level
dl = summaries$worst_day |>
  setNames(names(summaries$worst_day) |> stringr::str_replace_all("\n", " ")) |>
  download_this(
    output_name = "worst_days_by_provterr_" |>
      paste0(max(obs$date) |> format("%Y-%B")),
    output_extension = ".csv",
    sep = ",",
    dec = ".",
    button_label = "Download data as csv",
    button_type = "default",
    has_icon = TRUE,
    csv2 = FALSE,
    icon = "fa fa-save"
  )
table = reactable(
  data = summaries$worst_day,
  pagination = FALSE,
  defaultSorted = "Mean of Site Means",
  defaultSortOrder = "desc",
  columnGroups = list(
    reactable::colGroup(
      name = "PM2.5 Concentration (ug/m3)",
      columns = c(
        "Min of Site Means",
        "Mean of Site Means",
        "Max of Site Means"
      )
    )
  )
)

# Make download link and table for fcst zone level
pd = summaries$daily |>
  dplyr::group_by(nearest_community, date) |>
  dplyr::mutate(n_communities_ge_100 = as.numeric(pm25 >= 100)) |>
  dplyr::group_by(prov_terr, fcst_zone, date) |>
  dplyr::summarise(
    n_sites = n(),
    n_communities_ge_100 = nearest_community[n_communities_ge_100 == 1] |>
      unique() |>
      length(),
    n_sites_above_100 = sum(pm25 >= 100, na.rm = TRUE),
    mean_pm25 = round(mean(pm25, na.rm = TRUE), 1),
    min_pm25 = min(pm25, na.rm = TRUE),
    max_pm25 = max(pm25, na.rm = TRUE)
  ) |>
  dplyr::arrange(
    prov_terr,
    fcst_zone,
    desc(n_sites_above_100),
    desc(n_sites_above_100),
    desc(mean_pm25)
  ) |>
  dplyr::filter(!duplicated(`fcst_zone`)) |>
  dplyr::rename(worst_day = date) |>
  dplyr::mutate(
    n_ge_100 = paste0(
      n_sites_above_100,
      " / ",
      n_sites,
      " (",
      round(n_sites_above_100 / n_sites * 100, 1),
      "%)"
    ),
    worst_day = format(worst_day, "%B %d (%a)")
  ) |>
  dplyr::select(
    "Prov./Terr." = prov_terr,
    "Forecast Zone" = fcst_zone,
    "Worst Day" = worst_day,
    "Sites w/ Daily Mean Above 100 ug/m3" = n_ge_100,
    "Min of Sites" = min_pm25,
    "Mean of Sites" = mean_pm25,
    "Max of Sites" = max_pm25
  )
dl2 = pd |>
  download_this(
    output_name = "worst_days_by_fcast_zone_" |>
      paste0(max(obs$date) |> format("%Y-%B")),
    output_extension = ".csv",
    sep = ",",
    dec = ".",
    button_label = "Download data as csv",
    button_type = "default",
    has_icon = TRUE,
    csv2 = FALSE,
    icon = "fa fa-save"
  )
table2 = reactable(
  data = pd,
  groupBy = c("Prov./Terr."),
  defaultSorted = "Mean of Sites",
  defaultSortOrder = "desc",
  pagination = FALSE,
  columnGroups = list(
    reactable::colGroup(
      name = "Daily Site Mean PM2.5 Concentration (ug/m3)",
      columns = c("Min of Sites", "Mean of Sites", "Max of Sites")
    )
  )
)
```

::: card
::: card-body

<details>
<summary>Click for an automated text summary.</summary>

**STILL IN DEVELOPMENT**
  
</details>

:::
:::

`r tab_explainers$scale_tabs`

#### Province Level

::: card

::: {.card-img-top .p-2}

```{r include = TRUE, cache = FALSE}
dl
table
```

:::

::: card-body

The "worst day" for PM<sub>2.5</sub> concentrations **for each province**. The "worst day" is determined by the day with the most number of observation sites (FEM or PA) having a daily mean exceeding 100 {{< pm_units >}} with ties broken by the highest mean of the site daily mean concentrations across the province/territory.

:::

:::

#### Region Level

::: card

::: {.card-img-top .p-2}

```{r include = TRUE, cache=FALSE}
dl2
table2
```

:::

::: card-body

The "worst day" for PM<sub>2.5</sub> concentrations **for each forecast zone**. Click on the arrow beside a prov./terr. name to expand the table to view the zones for that area. The "worst day" is determined by the day with the most number of observation sites (FEM or PA) having a daily mean exceeding 100 {{< pm_units >}} with ties broken by the highest mean of the site daily mean concentrations across the province/territory.

:::

:::

### Which regions were most impacted, and for which days?

```{r analysis7, cache= FALSE}

dat1 = summaries$overall |>
  dplyr::group_by(prov_terr, fcst_zone) |>
  dplyr::summarise(
    pm25_mean_month = mean(pm25_mean, na.rm = TRUE) |> round(1),
    pm25_max_month = max(pm25_max, na.rm = TRUE),
    n_hours_above_60 = max(n_hours_above_60, na.rm = TRUE),
    n_hours_above_100 = max(n_hours_above_100, na.rm = TRUE),
    n_fem = sum(monitor == "FEM"),
    n_pa = sum(monitor == "PA"),
    n_monitors = n(),
    n_communities_w_data = length(unique(nearest_community)),
    n_communities_w_data_mean_ge_100 = nearest_community[pm25_mean >= 100] |>
      unique() |>
      length(),
    n_communities_w_data_max_ge_100 = nearest_community[pm25_max >= 100] |>
      unique() |>
      length(),
    days_w_over_100 = days_w_over_100_max |>
      stringr::str_split(",", simplify = TRUE) |>
      as.vector() |>
      unique() |>
      as.numeric() |>
      sort() |>
      shorten_number_list()
  ) |>
  dplyr::left_join(
    fcst_zones |> dplyr::select(fcst_zone, zone_prov = prov_terrs),
    by = "fcst_zone"
  ) |>
  dplyr::mutate(zone_prov = zone_prov |> stringr::str_replace("YT", "YK")) |>
  dplyr::mutate(
    fcst_zone = iconv(fcst_zone, to = "ASCII//TRANSLIT"),
    n_monitors = paste0(n_monitors, " (", n_fem, " FEM, ", n_pa, " PA)"),
    n_communities_w_data_mean_ge_100 = paste(
      n_communities_w_data_mean_ge_100,
      "/",
      n_communities_w_data
    ),
    n_communities_w_data_max_ge_100 = paste(
      n_communities_w_data_max_ge_100,
      "/",
      n_communities_w_data
    )
  ) |>
  dplyr::arrange(desc(n_hours_above_60)) |>
  dplyr::rename(
    "Prov./Terr." = `zone_prov`,
    "Forecast Zone" = fcst_zone,
    "# of Monitors" = n_monitors,
    "1-Month Mean (μg/m3)" = pm25_mean_month,
    "1-Month Max (μg/m3)" = pm25_max_month,
    "# of Communities\nw/ Mean > 100 μg/m3" = n_communities_w_data_mean_ge_100,
    "# of Communities\nw/ Max > 100 μg/m3" = n_communities_w_data_max_ge_100,
    "# Hours above 60 μg/m3" = n_hours_above_60,
    "# Hours above 100 μg/m3" = n_hours_above_100,
    "Day(s) of Month w/\n12+ hours Above 100 μg/m3" = days_w_over_100
  ) |>
  as.data.frame() |>
  dplyr::select(14, 2, 9, 3:4, 5:6, 13)

table = reactable(
  data = dat1,
  defaultSorted = c("# Hours above 60 μg/m3", "# Hours above 100 μg/m3"),
  defaultSortOrder = "desc",
  defaultPageSize = 15 #,
)
dl = dat1 |>
  setNames(names(dat1) |> stringr::str_replace_all("\n", " ")) |>
  dplyr::mutate(
    "Day(s) of Month w/ 12+ hours Above 100 μg/m3" = paste0(
      "'",
      `Day(s) of Month w/ 12+ hours Above 100 μg/m3`
    )
  ) |>
  download_this(
    output_name = "fcst_zone_pm25_summaries_" |>
      paste0(output_date_fmt),
    output_extension = ".csv",
    sep = ",",
    button_label = "Download data as csv",
    button_type = "default",
    has_icon = TRUE,
    csv2 = FALSE,
    icon = "fa fa-save"
  )
```

::: card
::: card-body

<details>
<summary>Click for an automated text summary.</summary>

**STILL IN DEVELOPMENT**
  
</details>

:::
:::

::: card

::: {.card-img-top .p-2}

```{r include = TRUE, cache=FALSE}
dl
table
```

:::

::: card-body

Summary of the PM<sub>2.5</sub> concentration data within each Canadian forecast zone. The table is interactive, filterable, and has multiple pages. The final column here highlights specific days with high smoke impacts.

:::

:::

##
